"""
Speech-to-Text Engine using OpenAI Whisper
Optimized for Polish language real-time processing

Autor: AI Assistant
Data: 2025-01-18
"""

import whisper
import numpy as np
import torch
import logging
import time
from typing import Optional, Dict, Any, List, Union
from dataclasses import dataclass
from enum import Enum
import threading
import queue

# Konfiguracja loggingu
logger = logging.getLogger(__name__)

class WhisperModel(Enum):
    """DostÄ™pne modele Whisper"""
    TINY = "tiny"
    BASE = "base" 
    SMALL = "small"
    MEDIUM = "medium"
    LARGE = "large"
    LARGE_V2 = "large-v2"
    LARGE_V3 = "large-v3"

@dataclass
class TranscriptionResult:
    """Wynik transkrypcji"""
    text: str
    language: str
    confidence: float
    processing_time: float
    segments: List[Dict[str, Any]]
    model_used: str
    
    @property
    def words_per_minute(self) -> float:
        """Oblicz sÅ‚owa na minutÄ™"""
        if self.processing_time <= 0:
            return 0
        word_count = len(self.text.split())
        return (word_count / self.processing_time) * 60

class WhisperSTTEngine:
    """
    Silnik Speech-to-Text oparty na OpenAI Whisper
    Zoptymalizowany dla jÄ™zyka polskiego
    """
    
    def __init__(
        self,
        model_name: Union[WhisperModel, str] = WhisperModel.MEDIUM,
        device: Optional[str] = None,
        language: str = "pl",
        beam_size: int = 5,
        best_of: int = 5,
        temperature: float = 0.0,
        patience: float = 1.0,
        length_penalty: float = 1.0,
        suppress_tokens: str = "-1",
        initial_prompt: Optional[str] = None,
        condition_on_previous_text: bool = True,
        fp16: bool = True,
        compression_ratio_threshold: float = 2.4,
        logprob_threshold: float = -1.0,
        no_speech_threshold: float = 0.6
    ):
        """
        Inicjalizacja Whisper STT Engine
        
        Args:
            model_name: Nazwa modelu Whisper (tiny, base, small, medium, large)
            device: Device do uÅ¼ywania ('cpu', 'cuda', None=auto)
            language: Kod jÄ™zyka (domyÅ›lnie 'pl' dla polskiego)
            beam_size: Rozmiar beam search
            best_of: Liczba kandydatÃ³w do wyboru
            temperature: Temperature dla sampling (0.0 = deterministyczny)
            patience: Patience factor dla beam search
            length_penalty: Penalty dla dÅ‚ugoÅ›ci sekwencji
            suppress_tokens: Tokeny do tÅ‚umienia
            initial_prompt: PoczÄ…tkowy prompt dla kontekstu
            condition_on_previous_text: Czy uÅ¼ywaÄ‡ poprzedniego tekstu jako kontekst
            fp16: Czy uÅ¼ywaÄ‡ half precision (szybsze, mniej pamiÄ™ci)
            compression_ratio_threshold: PrÃ³g dla wykrywania powtÃ³rzeÅ„
            logprob_threshold: PrÃ³g prawdopodobieÅ„stwa
            no_speech_threshold: PrÃ³g dla wykrywania braku mowy
        """
        self.model_name = model_name.value if isinstance(model_name, WhisperModel) else model_name
        self.language = language
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        # Parametry dekodowania
        self.decode_options = {
            "language": language,
            "beam_size": beam_size,
            "best_of": best_of,
            "temperature": temperature,
            "patience": patience,
            "length_penalty": length_penalty,
            "suppress_tokens": suppress_tokens,
            "initial_prompt": initial_prompt,
            "condition_on_previous_text": condition_on_previous_text,
            "fp16": fp16,
            "compression_ratio_threshold": compression_ratio_threshold,
            "logprob_threshold": logprob_threshold,
            "no_speech_threshold": no_speech_threshold
        }
        
        # Model i stan
        self.model = None
        self.is_loaded = False
        self.previous_text = ""
        
        # Statystyki
        self.total_transcriptions = 0
        self.total_processing_time = 0
        self.model_load_time = 0
        
        logger.info(f"ğŸ¤– WhisperSTTEngine inicjalizowany: model={self.model_name}, "
                   f"device={self.device}, language={language}")
    
    def load_model(self) -> bool:
        """
        ZaÅ‚aduj model Whisper
        
        Returns:
            True jeÅ›li zaÅ‚adowanie siÄ™ powiodÅ‚o
        """
        if self.is_loaded:
            logger.info("âœ… Model juÅ¼ zaÅ‚adowany")
            return True
        
        try:
            start_time = time.time()
            logger.info(f"ğŸ“¥ Åadowanie modelu Whisper: {self.model_name}")
            
            # ZaÅ‚aduj model z konfiguracjÄ…
            self.model = whisper.load_model(
                self.model_name,
                device=self.device
            )
            
            self.model_load_time = time.time() - start_time
            self.is_loaded = True
            
            logger.info(f"âœ… Model zaÅ‚adowany w {self.model_load_time:.2f}s")
            logger.info(f"ğŸ“Š Model info: {self.model_name} na {self.device}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d Å‚adowania modelu: {e}")
            self.is_loaded = False
            return False
    
    def transcribe_audio(
        self,
        audio_data: np.ndarray,
        sample_rate: int = 16000
    ) -> Optional[TranscriptionResult]:
        """
        Transkrybuj audio na tekst
        
        Args:
            audio_data: Dane audio jako numpy array
            sample_rate: CzÄ™stotliwoÅ›Ä‡ prÃ³bkowania
            
        Returns:
            TranscriptionResult lub None w przypadku bÅ‚Ä™du
        """
        if not self.is_loaded:
            if not self.load_model():
                return None
        
        try:
            start_time = time.time()
            
            # Przygotuj audio
            audio = self._prepare_audio(audio_data, sample_rate)
            
            # UÅ¼yj poprzedniego tekstu jako prompt jeÅ›li dostÄ™pny
            decode_options = self.decode_options.copy()
            if self.previous_text and decode_options.get("condition_on_previous_text", True):
                decode_options["initial_prompt"] = self.previous_text[-200:]  # Ostatnie 200 znakÃ³w
            
            # Transkrypcja
            result = self.model.transcribe(
                audio,
                **decode_options
            )
            
            processing_time = time.time() - start_time
            
            # Przygotuj wynik
            transcription_result = TranscriptionResult(
                text=result["text"].strip(),
                language=result["language"],
                confidence=self._calculate_confidence(result),
                processing_time=processing_time,
                segments=result.get("segments", []),
                model_used=self.model_name
            )
            
            # Aktualizuj statystyki
            self.total_transcriptions += 1
            self.total_processing_time += processing_time
            
            # Zachowaj tekst dla kontekstu
            if transcription_result.text:
                self.previous_text = transcription_result.text
            
            logger.debug(f"ğŸ¤ Transkrypcja: '{transcription_result.text}' "
                        f"({processing_time:.2f}s, conf={transcription_result.confidence:.2f})")
            
            return transcription_result
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d transkrypcji: {e}")
            return None
    
    def _prepare_audio(self, audio_data: np.ndarray, sample_rate: int) -> np.ndarray:
        """
        Przygotuj audio dla Whisper
        
        Args:
            audio_data: Surowe dane audio
            sample_rate: CzÄ™stotliwoÅ›Ä‡ prÃ³bkowania
            
        Returns:
            Przygotowane audio dla Whisper
        """
        # Whisper oczekuje 16kHz mono float32
        audio = audio_data.astype(np.float32)
        
        # Flatten jeÅ›li stereo
        if len(audio.shape) > 1:
            audio = audio.flatten()
        
        # Resample jeÅ›li potrzeba (Whisper uÅ¼ywa 16kHz)
        if sample_rate != 16000:
            # Prosty resampling - w produkcji uÅ¼yj librosa.resample
            audio = self._simple_resample(audio, sample_rate, 16000)
        
        # Normalizacja
        if audio.max() > 1.0 or audio.min() < -1.0:
            audio = audio / max(abs(audio.max()), abs(audio.min()))
        
        # Whisper wymaga minimum 0.1s audio
        min_samples = int(0.1 * 16000)
        if len(audio) < min_samples:
            audio = np.pad(audio, (0, min_samples - len(audio)))
        
        return audio
    
    def _simple_resample(self, audio: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """
        Prosty resampling audio
        
        Args:
            audio: Audio do resample
            orig_sr: Oryginalna czÄ™stotliwoÅ›Ä‡
            target_sr: Docelowa czÄ™stotliwoÅ›Ä‡
            
        Returns:
            Resampled audio
        """
        if orig_sr == target_sr:
            return audio
        
        # Prosty linear interpolation resampling
        ratio = target_sr / orig_sr
        new_length = int(len(audio) * ratio)
        
        # Linear interpolation
        old_indices = np.linspace(0, len(audio) - 1, new_length)
        new_audio = np.interp(old_indices, np.arange(len(audio)), audio)
        
        return new_audio.astype(np.float32)
    
    def _calculate_confidence(self, result: Dict[str, Any]) -> float:
        """
        Oblicz wskaÅºnik pewnoÅ›ci transkrypcji
        
        Args:
            result: Wynik Whisper
            
        Returns:
            Confidence score 0-1
        """
        try:
            # UÅ¼yj Å›redniego logprob z segmentÃ³w
            segments = result.get("segments", [])
            if not segments:
                return 0.5  # DomyÅ›lna wartoÅ›Ä‡
            
            logprobs = []
            for segment in segments:
                if "avg_logprob" in segment:
                    logprobs.append(segment["avg_logprob"])
                elif "tokens" in segment:
                    # Fallback - uÅ¼yj liczby tokenÃ³w jako proxy
                    logprobs.append(-0.1 * len(segment["tokens"]))
            
            if logprobs:
                avg_logprob = np.mean(logprobs)
                # Konwertuj logprob na confidence (0-1)
                confidence = max(0.0, min(1.0, (avg_logprob + 2.0) / 2.0))
                return confidence
            
            return 0.5
            
        except Exception as e:
            logger.warning(f"âš ï¸ BÅ‚Ä…d obliczania confidence: {e}")
            return 0.5
    
    def get_model_info(self) -> Dict[str, Any]:
        """Pobierz informacje o modelu"""
        return {
            "model_name": self.model_name,
            "device": self.device,
            "language": self.language,
            "is_loaded": self.is_loaded,
            "load_time": self.model_load_time,
            "total_transcriptions": self.total_transcriptions,
            "avg_processing_time": (
                self.total_processing_time / max(self.total_transcriptions, 1)
            ),
            "decode_options": self.decode_options
        }
    
    def get_supported_languages(self) -> List[str]:
        """Pobierz listÄ™ obsÅ‚ugiwanych jÄ™zykÃ³w"""
        if not self.is_loaded:
            self.load_model()
        
        if self.model:
            return list(whisper.tokenizer.LANGUAGES.values())
        return []
    
    def clear_context(self):
        """WyczyÅ›Ä‡ kontekst poprzedniego tekstu"""
        self.previous_text = ""
        logger.info("ğŸ§¹ Kontekst tekstowy wyczyszczony")
    
    def set_language(self, language: str):
        """
        Ustaw jÄ™zyk transkrypcji
        
        Args:
            language: Kod jÄ™zyka (np. 'pl', 'en')
        """
        self.language = language
        self.decode_options["language"] = language
        logger.info(f"ğŸŒ JÄ™zyk ustawiony na: {language}")
    
    def unload_model(self):
        """Zwolnij model z pamiÄ™ci"""
        if self.model is not None:
            del self.model
            self.model = None
            self.is_loaded = False
            
            # WyczyÅ›Ä‡ cache GPU jeÅ›li uÅ¼ywane
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            logger.info("ğŸ—‘ï¸ Model Whisper zwolniony z pamiÄ™ci")
    
    def __enter__(self):
        """Context manager entry"""
        self.load_model()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit"""
        self.unload_model()


class PolishOptimizedSTT(WhisperSTTEngine):
    """
    Whisper STT Engine zoptymalizowany specjalnie dla jÄ™zyka polskiego
    """
    
    def __init__(self, **kwargs):
        """
        Inicjalizacja z optymalizacjami dla polskiego
        """
        # Optymalne ustawienia dla polskiego
        polish_defaults = {
            "language": "pl",
            "initial_prompt": "To jest nagranie w jÄ™zyku polskim. ",
            "beam_size": 5,
            "best_of": 5,
            "temperature": 0.0,
            "patience": 1.0,
            "no_speech_threshold": 0.5  # NiÅ¼szy prÃ³g dla polskiego
        }
        
        # Merge z user settings
        for key, value in polish_defaults.items():
            kwargs.setdefault(key, value)
        
        super().__init__(**kwargs)
        
        # Polskie stopwords i frazy
        self.polish_common_words = {
            "tak", "nie", "jest", "to", "na", "w", "z", "siÄ™", "Å¼e", "do", "i", "a", "o",
            "ale", "jego", "jej", "ich", "my", "wy", "oni", "one", "jak", "co", "gdy",
            "gdzie", "dlaczego", "ktÃ³ry", "ktÃ³ra", "ktÃ³re", "bardzo", "moÅ¼e", "moÅ¼e byÄ‡"
        }
        
        logger.info("ğŸ‡µğŸ‡± PolishOptimizedSTT zainicjalizowany z optymalizacjami dla polskiego")
    
    def post_process_polish_text(self, text: str) -> str:
        """
        Post-processing specyficzny dla polskiego jÄ™zyka
        
        Args:
            text: Surowy tekst z Whisper
            
        Returns:
            Przetworzony tekst
        """
        if not text:
            return text
        
        # Podstawowe poprawki dla polskiego
        corrections = {
            # CzÄ™ste bÅ‚Ä™dy Whisper dla polskiego (brak polskich znakÃ³w)
            " sie ": " siÄ™ ",   # siÄ™
            " ze ": " Å¼e ",     # Å¼e (tylko jeÅ›li poprzedzone spacjÄ…)
            "ze ": "Å¼e ",       # Å¼e na poczÄ…tku
        }
        
        processed_text = text
        
        # Zastosuj podstawowe korekty
        for wrong, correct in corrections.items():
            if wrong in processed_text.lower():
                # Zachowaj oryginalne wielkoÅ›ci liter
                processed_text = processed_text.replace(wrong, correct)
        
        # Kapitalizacja pierwszej litery
        if processed_text:
            processed_text = processed_text[0].upper() + processed_text[1:]
        
        return processed_text.strip()
    
    def transcribe_audio(self, audio_data: np.ndarray, sample_rate: int = 16000) -> Optional[TranscriptionResult]:
        """
        Transkrypcja z post-processingiem dla polskiego
        """
        result = super().transcribe_audio(audio_data, sample_rate)
        
        if result and result.text:
            # Zastosuj post-processing dla polskiego
            original_text = result.text
            processed_text = self.post_process_polish_text(original_text)
            
            # UtwÃ³rz nowy wynik z przetworzonym tekstem
            result = TranscriptionResult(
                text=processed_text,
                language=result.language,
                confidence=result.confidence,
                processing_time=result.processing_time,
                segments=result.segments,
                model_used=result.model_used
            )
            
            if processed_text != original_text:
                logger.debug(f"ğŸ‡µğŸ‡± Polish post-processing: '{original_text}' -> '{processed_text}'")
        
        return result
